{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "joint_angles_df = pd.read_csv('/mnt/data/joint_angles.csv')\n",
    "poi_metrics_df = pd.read_csv('/mnt/data/poi_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb756987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "joint_angles_df =  pd.read_csv(r\"C:\\Users\\conne\\Documents\\GitHub\\openbiomechanics\\baseball_pitching\\data\\full_sig\\joint_angles.csv\")\n",
    "poi_metrics_df =  pd.read_csv(r\"C:\\Users\\conne\\Documents\\GitHub\\openbiomechanics\\baseball_pitching\\data\\poi\\poi_metrics.csv\")\n",
    "\n",
    "# Filter the relevant columns from both datasets before merging\n",
    "filtered_joint_angles_df = joint_angles_df.iloc[:, :-5]\n",
    "filtered_poi_metrics_df = poi_metrics_df[['session_pitch', 'session', 'pitch_speed_mph']]\n",
    "\n",
    "# Merge the two datasets based on the 'session_pitch' variable\n",
    "merged_df = pd.merge(filtered_joint_angles_df, filtered_poi_metrics_df, on='session_pitch')\n",
    "\n",
    "# Filter the data to include only the specified pitches: 1097_1, 1097_2, 1097_3\n",
    "df_filtered_1097 = merged_df[merged_df['session_pitch'].isin(['1097_1', '1097_2', '1097_3'])]\n",
    "\n",
    "# Identify the slowest pitch in the session based on pitch speed\n",
    "slowest_pitch = df_filtered_1097.loc[df_filtered_1097['pitch_speed_mph'].idxmin()]['session_pitch']\n",
    "\n",
    "# Initialize an empty dataframe to store the trimmed data\n",
    "df_trimmed_1097 = pd.DataFrame()\n",
    "\n",
    "# Find unique pitch sessions for the filtered data\n",
    "unique_pitches_1097 = df_filtered_1097['session_pitch'].unique()\n",
    "\n",
    "# Initialize variable to store the length of the shortest time series\n",
    "min_length_1097 = float('inf')\n",
    "\n",
    "# Loop through each unique pitch to trim and crop the data\n",
    "for pitch in unique_pitches_1097:\n",
    "    df_pitch = df_filtered_1097[df_filtered_1097['session_pitch'] == pitch]\n",
    "    \n",
    "    # Find the time of the peak leg lift\n",
    "    peak_leg_lift_time = df_pitch['pkh_time'].iloc[0]\n",
    "    \n",
    "    # Trim the series to start at the peak of the leg lift\n",
    "    df_trim = df_pitch[df_pitch['time'] >= peak_leg_lift_time]\n",
    "    \n",
    "    # Update the 'time' variable so it starts from 0 and increments by 1\n",
    "    df_trim['time'] = range(len(df_trim))\n",
    "    \n",
    "    # Update the minimum length\n",
    "    min_length_1097 = min(min_length_1097, len(df_trim))\n",
    "    \n",
    "    # Append to the trimmed dataframe\n",
    "    df_trimmed_1097 = pd.concat([df_trimmed_1097, df_trim])\n",
    "\n",
    "# Make each time series the same length by trimming to the shortest one\n",
    "df_final_1097 = pd.DataFrame()\n",
    "for pitch in unique_pitches_1097:\n",
    "    df_pitch = df_trimmed_1097[df_trimmed_1097['session_pitch'] == pitch]\n",
    "    df_final_1097 = pd.concat([df_final_1097, df_pitch.iloc[:min_length_1097]])\n",
    "\n",
    "# Show the first few rows of the final trimmed and cropped dataframe\n",
    "trimmed_dfs = df_final_1097\n",
    "\n",
    "scores = {}\n",
    "        \n",
    "for col in trimmed_dfs.columns[3:-1]:\n",
    "            \n",
    "    sums =  0\n",
    "            \n",
    "    for t in range(0, min_length_1097):\n",
    "            \n",
    "        slowest_value = trimmed_dfs[(trimmed_dfs['session_pitch'] == slowest_pitch) & (trimmed_dfs['time'] == t)][col].iloc[0]\n",
    "        #slowest_value = trimmed_dfs.query(f\"session_pitch == '{slowest_pitch}' and time == {t}\")[col].iloc[]\n",
    "        other_values = trimmed_dfs[(trimmed_dfs['session_pitch'] != slowest_pitch) & (trimmed_dfs['time'] == t)][col]\n",
    "        average_value = sum(other_values)/(len(trimmed_dfs['session_pitch'].unique()) - 1)\n",
    "        diff = abs(slowest_value - average_value)\n",
    "        sums += (diff * ((min_length_1097 - t)/min_length_1097))\n",
    "    \n",
    "    \n",
    "    multiplier = 0.5  # Default multiplier\n",
    "    if any(keyword in col for keyword in ['ankle', 'knee', 'hip', 'pelvis']):\n",
    "        multiplier = 1.5\n",
    "    elif any(keyword in col for keyword in ['torso', 'shoulder']):\n",
    "        multiplier = 1.0\n",
    "            \n",
    "    scores[col] = (sums/min_length_1097) * multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores_dict = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Pick the top 3 variables\n",
    "top_3_vars = list(sorted_scores_dict.keys())[:3]\n",
    "\n",
    "# Plot the time series for the top 3 variables\n",
    "for var in top_3_vars:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for pitch in df_filtered_1097['session_pitch'].unique():\n",
    "        plt.plot(df_filtered_1097[df_filtered_1097['session_pitch'] == pitch]['time'],\n",
    "                 df_filtered_1097[df_filtered_1097['session_pitch'] == pitch][var],\n",
    "                 label=f\"Pitch: {pitch.split('_')[1]}\")\n",
    "    plt.title(f\"Time Series for {var} in Session 1097\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(var)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134c1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3ef90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9164fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "joint_angles_df = pd.read_csv('/mnt/data/joint_angles.csv')\n",
    "poi_metrics_df = pd.read_csv('/mnt/data/poi_metrics.csv')\n",
    "\n",
    "# Merge the datasets\n",
    "joint_angles_df = joint_angles_df.merge(poi_metrics_df[['session_pitch', 'pitch_speed_mph']], on='session_pitch', how='inner')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "joint_angles_df = joint_angles_df.drop(joint_angles_df.columns[-6:], axis=1)\n",
    "\n",
    "# Group the data by session\n",
    "grouped_by_session = joint_angles_df.groupby(joint_angles_df['session_pitch'].str.split('_').str[0])\n",
    "\n",
    "# Define a function to perform DTW algorithm from scratch\n",
    "def dtw_distance(s1, s2):\n",
    "    DTW = {}\n",
    "    \n",
    "    for i in range(len(s1)):\n",
    "        DTW[(i, -1)] = float('inf')\n",
    "    for i in range(len(s2)):\n",
    "        DTW[(-1, i)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            dist = abs(s1[i] - s2[j])\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)], DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "            \n",
    "    return DTW[len(s1)-1, len(s2)-1]\n",
    "\n",
    "# Filter for players with a slowest pitch that is more than 1 std dev below the average\n",
    "filtered_sessions = []\n",
    "for session, session_data in grouped_by_session:\n",
    "    avg_speed = session_data.groupby('session_pitch')['pitch_speed_mph'].first().mean()\n",
    "    std_speed = session_data.groupby('session_pitch')['pitch_speed_mph'].first().std()\n",
    "    slowest_pitch = session_data.groupby('session_pitch')['pitch_speed_mph'].first().idxmin()\n",
    "    slowest_speed = session_data.loc[session_data['session_pitch'] == slowest_pitch, 'pitch_speed_mph'].iloc[0]\n",
    "    \n",
    "    if slowest_speed <= avg_speed - std_speed:\n",
    "        filtered_sessions.append(session)\n",
    "\n",
    "# Pick a random session to analyze\n",
    "random_session = np.random.choice(filtered_sessions)\n",
    "\n",
    "# Filter the data for this session\n",
    "random_session_data = joint_angles_df[joint_angles_df['session_pitch'].str.contains(random_session)]\n",
    "\n",
    "# Identify the 'slowest' pitch in the session\n",
    "slowest_pitch = random_session_data.groupby('session_pitch')['pitch_speed_mph'].first().idxmin()\n",
    "slowest_pitch_data = random_session_data[random_session_data['session_pitch'] == slowest_pitch]\n",
    "\n",
    "# Prepare a dictionary to store DTW distances for each biomechanical variable in the session\n",
    "session_dtw_dict = {}\n",
    "\n",
    "# Loop through each biomechanical variable\n",
    "for col in random_session_data.columns[3:-1]:\n",
    "    dtw_distances = []\n",
    "    for pitch in random_session_data['session_pitch'].unique():\n",
    "        if pitch == slowest_pitch:\n",
    "            continue\n",
    "        slowest_pitch_series = slowest_pitch_data[col].values\n",
    "        current_pitch_series = random_session_data[random_session_data['session_pitch'] == pitch][col].values\n",
    "        distance = dtw_distance(slowest_pitch_series, current_pitch_series)\n",
    "        dtw_distances.append(distance)\n",
    "    avg_dtw_distance = np.mean(dtw_distances)\n",
    "    session_dtw_dict[col] = avg_dtw_distance\n",
    "\n",
    "# Sort the dictionary by DTW distance to identify the variables with the most significant deviations\n",
    "sorted_dtw_dict = {k: v for k, v in sorted(session_dtw_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Pick the top 3 variables\n",
    "top_3_vars = list(sorted_dtw_dict.keys())[:3]\n",
    "\n",
    "# Plot the time series for the top 3 variables\n",
    "for var in top_3_vars:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for pitch in random_session_data['session_pitch'].unique():\n",
    "        plt.plot(random_session_data[random_session_data['session_pitch'] == pitch]['time'],\n",
    "                 random_session_data[random_session_data['session_pitch'] == pitch][var],\n",
    "                 label=f\"Pitch: {pitch.split('_')[1]}\")\n",
    "    plt.title(f\"Time Series for {var} in Session {random_session}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(var)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1927fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ecd61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from heapq import nlargest\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the datasets\n",
    "joint_angles_df =  pd.read_csv(r\"C:\\Users\\conne\\Documents\\GitHub\\openbiomechanics\\baseball_pitching\\data\\full_sig\\joint_angles.csv\")\n",
    "poi_metrics_df =  pd.read_csv(r\"C:\\Users\\conne\\Documents\\GitHub\\openbiomechanics\\baseball_pitching\\data\\poi\\poi_metrics.csv\")\n",
    "\n",
    "# Filter the relevant columns from both datasets before merging\n",
    "filtered_joint_angles_df = joint_angles_df.iloc[:, :-5]\n",
    "filtered_poi_metrics_df = poi_metrics_df[['session_pitch', 'session', 'pitch_speed_mph']]\n",
    "\n",
    "# Merge the two datasets based on the 'session_pitch' variable\n",
    "merged_df = pd.merge(filtered_joint_angles_df, filtered_poi_metrics_df, on='session_pitch')\n",
    "\n",
    "# Re-initialize the dictionary to store the 'root cause' variables for each pitcher\n",
    "root_cause_dict = {}\n",
    "\n",
    "# Loop through each unique session (pitcher)\n",
    "for session in merged_df['session'].unique():\n",
    "    \n",
    "    # Filter data for the current session (pitcher)\n",
    "    session_data = merged_df[merged_df['session'] == session]\n",
    "    \n",
    "    # Identify the slowest pitch in the session based on pitch speed\n",
    "    slowest_pitch = session_data.loc[session_data['pitch_speed_mph'].idxmin()]['session_pitch']\n",
    "    \n",
    "    # Calculate the mean and standard deviation for pitch speeds, excluding the slowest pitch\n",
    "    mean_speed = np.mean(session_data[session_data['session_pitch'] != slowest_pitch]['pitch_speed_mph'])\n",
    "    std_speed = np.std(session_data[session_data['session_pitch'] != slowest_pitch]['pitch_speed_mph'])\n",
    "    \n",
    "    # Calculate the Z-score for the slowest pitch\n",
    "    z_score_slowest = (session_data.loc[session_data['pitch_speed_mph'].idxmin()]['pitch_speed_mph'] - mean_speed) / std_speed\n",
    "    \n",
    "    # If the slowest pitch is significantly slower (Z-score <= -1), then proceed with analysis\n",
    "    if z_score_slowest <= -1:\n",
    "        \n",
    "        df_filtered = session_data\n",
    "        \n",
    "        # Initialize an empty dataframe to store the trimmed data\n",
    "        df_trimmed = pd.DataFrame()\n",
    "\n",
    "        # Find unique pitch sessions for the filtered data\n",
    "        unique_pitches = df_filtered['session_pitch'].unique()\n",
    "\n",
    "        # Initialize variable to store the length of the shortest time series\n",
    "        min_length = float('inf')\n",
    "\n",
    "        # Loop through each unique pitch to trim and crop the data\n",
    "        for pitch in unique_pitches:\n",
    "            df_pitch = df_filtered[df_filtered['session_pitch'] == pitch]\n",
    "    \n",
    "            # Find the time of the peak leg lift\n",
    "            peak_leg_lift_time = df_pitch['pkh_time'].iloc[0]\n",
    "    \n",
    "            # Trim the series to start at the peak of the leg lift\n",
    "            df_trim = df_pitch[df_pitch['time'] >= peak_leg_lift_time]\n",
    "    \n",
    "            # Update the 'time' variable so it starts from 0 and increments by 1\n",
    "            df_trim['time'] = range(len(df_trim))\n",
    "    \n",
    "            # Update the minimum length\n",
    "            min_length = min(min_length, len(df_trim))\n",
    "    \n",
    "            # Append to the trimmed dataframe\n",
    "            df_trimmed = pd.concat([df_trimmed, df_trim])\n",
    "\n",
    "        # Make each time series the same length by trimming to the shortest one\n",
    "        df_final = pd.DataFrame()\n",
    "        for pitch in unique_pitches:\n",
    "            df_pitch = df_trimmed[df_trimmed['session_pitch'] == pitch]\n",
    "            df_final = pd.concat([df_final, df_pitch.iloc[:min_length]])\n",
    "\n",
    "        # Show the first few rows of the final trimmed and cropped dataframe\n",
    "        trimmed_dfs = df_final\n",
    "            \n",
    "        scores = {}\n",
    "        \n",
    "        for col in trimmed_dfs.columns[3:-1]:\n",
    "            \n",
    "            sums =  0\n",
    "            \n",
    "            for t in range(0, min_length):\n",
    "            \n",
    "                slowest_value = trimmed_dfs[(trimmed_dfs['session_pitch'] == slowest_pitch) & (trimmed_dfs['time'] == t)][col].iloc[0]\n",
    "                #slowest_value = trimmed_dfs.query(f\"session_pitch == '{slowest_pitch}' and time == {t}\")[col].iloc[0]\n",
    "                #print(slowest_value)\n",
    "                other_values = trimmed_dfs[(trimmed_dfs['session_pitch'] != slowest_pitch) & (trimmed_dfs['time'] == t)][col]\n",
    "                average_value = sum(other_values)/(len(trimmed_dfs['session_pitch'].unique()) - 1)\n",
    "                diff = abs(slowest_value - average_value)\n",
    "                sums += (diff * (min_length - t))\n",
    "                         \n",
    "            multiplier = 0.5  # Default multiplier\n",
    "            if any(keyword in col for keyword in ['ankle', 'knee', 'hip', 'pelvis']):\n",
    "                multiplier = 1.5\n",
    "            elif any(keyword in col for keyword in ['torso', 'shoulder']):\n",
    "                multiplier = 1.0\n",
    "            \n",
    "            scores[col] = (sums/min_length) * multiplier\n",
    "        \n",
    "        \n",
    "        top_3_vars = nlargest(3, sample_dict, key=sample_dict.get)\n",
    "        top_3_items = {k: sample_dict[k] for k in top_3_vars}\n",
    "        \n",
    "        root_cause_dict[session] = top_3_items\n",
    "        \n",
    "\n",
    "var_frequency = Counter()\n",
    "\n",
    "for inner_dict in root_cause_dict.values():\n",
    "    var_frequency.update(inner_dict.keys())\n",
    "\n",
    "var_frequency\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7deb7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_cause_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c0eab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2889"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(root_cause_dict, key=root_cause_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73494183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6ba9135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['b', 'd', 'c'], {'b': 5, 'd': 4, 'c': 3})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample code to demonstrate getting the 3 elements in a dictionary with the highest values\n",
    "from heapq import nlargest\n",
    "\n",
    "# Sample dictionary\n",
    "sample_dict = {'a': 1, 'b': 5, 'c': 3, 'd': 4, 'e': 2}\n",
    "\n",
    "# Get the 3 keys with the highest values\n",
    "top_3_keys = nlargest(3, sample_dict, key=sample_dict.get)\n",
    "\n",
    "# Get the 3 highest key-value pairs\n",
    "top_3_items = {k: sample_dict[k] for k in top_3_keys}\n",
    "\n",
    "top_3_keys, top_3_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b69263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
